---
layout: post
title:  "Robotic stippling: Minimizing makespan for multi-robot stippling"
subtitle: "or: Abusing lab equipment v4 - but this time for science!"
date:   2023-09-10 12:00:00 +0200
permalink: /low-makespan-tamp/
categories: art 
---

<p class="preface">
    In this series, I looked at overengineering 'making dots on a piece of paper' by using multiple robots.
    In part 1 we looked at making stippling work for a single robot, and in part 2, we extended this to two robots.
    In part 3, we had a look at approaches that optimize the order for the single-robot case.
    
    This here is a writeup of a paper I wrote as follow up, which is hopefully a bit more accessible than the paper itself.
</p>

In previous posts, I looked at finding poses for robot arms to make dots, sorting the poses, and then finding paths for one robot in [part 1](/robo-stippling/), and for two robots in [part 2](/robo-stippling-p2/).
In [part 3](/optimal-stippling/) we had a look at sorting the sequences for the single robot case to find the optimal order to minimize the makespan.

In the [paper](https://arxiv.org/abs/2305.17527) I had a look at optimizing paths and sequences for multiple robots.
There are multiple caveats in the appraoch, which means that the solution that we get out is not _the_ optimal solution, but it is a better one than various baselines.

Code is available [on github](https://github.com/vhartman/planrob-23-low-makespan), and the version of the code that was used to produce the data that is in the paper is [here](https://github.com/vhartman/planrob-23-low-makespan/releases/tag/paper-version).

#### Problem setting
The problem setting I am interested in is mostly the same as before:
We are given a set of dots, and I want to figure out how to minimize the time it takes to make all of them with multiple robots.{% include sidenote.html text='There is one major caveat to this very generic problem setting above: For now, we only consider a single pose per robot that makes this dot (in reality, there are clearly multiple poses in which the arm makes the same dot).' %}

The questions we need to answer are then:
- which robot makes which dot?
- in which order should the dots be made?
- how does the robot need to move between the dot-making-poses?

This can be formalized into an optimization problem, but since that is not solvable by any solver that I know (and there most likely is no solver that is able to solve such a problem using optimization based approaches), I'll skip this here.
Interested readers should definitely have alook at the paper.

I generalized the problem above slightly in the paper: I do want to be able to use the approach for not only the dot-making setting, but I care about generic sets of tasks that can be distributed over multiple robots. In the paper, the example I use is bin-picking with two robot arms.
This does not change anything majorly in the problem setting that we used in the previous parts.

#### Method
The core idea in the paper is that we can simpy search over all possible orders and assignments if we find a suitable representation of the task sequence.
The difficult part for me was to actually figure out some representation that enables planning for a given order of tasks and assignment to robots.

I ended up doing it as follows:

[]

Then, for computing a plan for this specific assignment and task order, we use the framework I developed in the [paper here](/multi-robot/).
I'll recap the approach briefly (hopefully in a more approachable manner than in the paper):

The approach is based on decomposing the complete sequence into the separate tasks.
Then, a planning problem only deals with a single robot, and a single objective (i.e., make a dot).
The core issue is then how to take previous solutions into account when planning the movement for the next task.

What I realized at some point after I wrote the paper is that this approach is a version of prioritized planning.
Particularly, in our setting, our priorizatoin is strictly given by when the task occurrs in the sequence we made up before.

#### Experiments
For the paper, I did not only look at stippling, but also at a bin picking scenario.

The scenarios we looked at were the following:

<div style="width: 90%;margin:auto">
    <img src="{{ site.url }}/assets/stippling/p3/grid.png" style="width:25%; padding: 5px">
    <img src="{{ site.url }}/assets/stippling/p3/logo.png" style="width:25%; padding: 5px">
    <img src="{{ site.url }}/assets/low-makespan/bin-picking-scenario.png" style="width:40%; padding: 5px">
</div>

Fof the stippling problems, I looked at multiple versions with different numbers of robots, and for the logo specifically, I also had a look at a large version, and a smaller version.
The larger version is well parallelizable, whereas the small version is too small to be worked on by multiple robots simultaneously.

#### Results
There is a full playlist of both simulations and real world execution [here](/seq-opt/).
I'll put a few gifs and videos here, but I encourage you to actually look at the playlist above.

Below is the bin-picking scenario. On the left, the greedy (alternating between the two arms) version is shown, and on the right, the optimized variant can be seen.{% include sidenote.html text='Refresh the page for starting them at the same time.' %}
<div style="width: 85%;margin:auto">
    <img src="{{ site.url }}/assets/low-makespan/bin_picking_two_arms_greedy_2.gif" style="width:45%; padding: 5px">
    <img src="{{ site.url }}/assets/low-makespan/bin_picking_two_arms_opt.gif" style="width:45%; padding: 5px">
</div>

The execution of the optimized version on real robots look like this:

<iframe style="display:block; margin: 0 auto;" width="600px" height="340" src="https://www.youtube.com/embed/-Ttx2oUxV68?list=PLsgBOepATbbatyInqU5qSk_qjg-jqD4G3" title="[OptSequence] LIS Large optimized sequence" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

I also made some quantitative compairsons, in the form of a few plots that show the evolution of the makespan over the runtime, and a comparison to some baselines.

First, there are the grid-scenarios with 2 and 4 robots respectively. On the case of the 4 robots, the single-arm comparison is not present since some of the points are not reachable by some of the robots.

<div style="width: 95%;margin:auto">
    <img src="{{ site.url }}/assets/low-makespan/grid_stippling.png" style="width:100%; padding: 5px">
</div>

And the same plot for the bin-pickign setting:

<div style="width: 95%;margin:auto">
    <img src="{{ site.url }}/assets/low-makespan/bin-picking.png" style="width:47%; padding: 5px; display:block;margin-left:auto; margin-right:auto">
</div>

Generally, we can see that the algorithm does what it is supposed to do: decreasing the makespan over time by trying different sequences.
I do believe that with more runtime, this would eventually find the minimum makespan for the planning method we use.

A quick word about planning times: for [], the planning times per sequence are roughly []. 
For [], the planning times per sequence are roughly [].
That is, the planning times are relatively long, and are (obviously) the major part of the planning time.

#### Limitations
As disussed, the approach presented here is essentially a prioritized search.
This is clearly suboptimal.

This whole thing is also relatively slow.


#### Outlook
The outlook is perfectly correlated with the limitations.
What I am interested in as direct follow up is the following:

- Making this a copmlete TAMP approach, i.e., dealing with task-search properly, enabling more skills (such as drawing lines), and enabling actions that require coordination between robots.
- I do have a few videos for demonstration pruposes of the paths that are produced. However, those are open-loop, and sometimes the robots smash the pens into the paper. There are two main things here: we need to deal with disturbances during execution, and we need to deal with sensor feedback.
- Speeding everyhting up.
- Figuring out how suboptimal this approach is.
